# WanderAI: Core LLM Journey Engine

WanderAI is a high-performance, modular collection of LLM-powered agents designed to build intelligent travel planning pipelines. This repository focuses on the stable **M1-M3 Agent Core**, delivering a seamless flow from natural language intent to detailed, actionable itineraries.

## ğŸš€ Key Features

- **Agent-Grade Robustness**: Every module features ultra-robust Pydantic models with aggressive structural repair and key mapping.
- **Universal JSON Recovery**: The `LLMClient` salvaged valid data from messy LLM outputs through deep structural normalization.
- **Unified LLM Intelligence**: Built-in support for Groq (Llama 3) and Gemini with automatic fallback logic.
- **RAG-Powered Personalization**: Keyword-based Retrieval-Augmented Generation for locally grounded destination suggestions.
- **Conversational Engine**: A state-aware chatbot controller that handles follow-ups, context, and flexible travel queries.
- **Backend Ready**: Includes a dedicated integration guide and reusable engine for seamless API development.
- **Production-Ready Demo**: High-polish terminal interfaces (`run.py` and `chatbot.py`) to experience the full agentic flow.

## ğŸ› ï¸ Project Structure

```text
â”œâ”€â”€ modules/               # Core LLM Agent Modules
â”‚   â”œâ”€â”€ m1_intent_extractor.py     # Parses raw queries into structured intents
â”‚   â”œâ”€â”€ m2_destination_suggester.py # RAG-based personalized recommendations
â”‚   â””â”€â”€ m3_itinerary_builder.py    # Generates detailed day-by-day plans
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ llm_client.py      # Unified API wrapper with deep repair
â”‚   â””â”€â”€ rag_engine.py      # Keyword-based RAG engine
â”œâ”€â”€ knowledge_base/        # RAG Data (JSON)
â”œâ”€â”€ config.py              # Environment configuration
â”œâ”€â”€ run.py                 # Linear Pipeline Demo
â”œâ”€â”€ chatbot.py             # Conversational Chatbot Demo
â”œâ”€â”€ api_example.py         # Backend Integration Example
â”œâ”€â”€ BACKEND_INTEGRATION.md # Developer Guide for Backend Integration
â”œâ”€â”€ requirements.txt       # Project dependencies
â””â”€â”€ .env                   # API Keys (Git ignored)
```

## ğŸš¥ Quick Start

### 1. Setup Environment
```bash
pip install -r requirements.txt
```

### 2. Configure API Keys
Create a `.env` file in the root directory:
```env
GROQ_API_KEY=your_groq_key_here
GEMINI_API_KEY=your_gemini_key_here
PRIMARY_LLM=groq
```

### 3. Experience the Flow
- **Linear Pipeline**: `python run.py` (M1 -> M2 -> M3)
- **Conversational Chatbot**: `python chatbot.py` (End-to-end with history and context)

## ğŸ› ï¸ Backend Integration
If you are integrating these modules into a web backend (FastAPI, Node.js, etc.), please refer to **[BACKEND_INTEGRATION.md](file:///d:/AMD_Hackathon/wanderai_llm_modules/BACKEND_INTEGRATION.md)** for architecture recommendations and code examples.

## ğŸ¤– Core Pipeline

1.  **M1: Intent Extractor**: Converts messy user queries into clean data (budget, duration, group size, interests).
2.  **M2: Destination Suggester**: Matches intent against the local knowledge base to suggest the best locations.
3.  **M3: Itinerary Builder**: Generates specific timings, activities, and cost estimates for each day of the trip.

## ğŸ”§ Integration & Extensibility

The system is designed to be modular. You can swap out the RAG engine, add specialized ML prediction modules (for crowd or experience scores), or plug the modules into a FastAPI/Express backend.

## ğŸ“„ License

MIT License - Free for experimental and commercial use.
